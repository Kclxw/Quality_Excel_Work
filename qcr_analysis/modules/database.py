# -*- coding: utf-8 -*-
"""
=============================================================================
æ•°æ®åº“æ“ä½œæ¨¡å—
=============================================================================
è´Ÿè´£ä¸MySQLæ•°æ®åº“çš„äº¤äº’ï¼ŒåŒ…æ‹¬ï¼š
- è¿æ¥ç®¡ç†
- æ•°æ®å»é‡
- æ•°æ®å¯¼å…¥
- å­—æ®µæ˜ å°„å’Œæ¸…æ´—
=============================================================================
"""

import pandas as pd
from sqlalchemy import create_engine, text
from pathlib import Path
from typing import Optional

import sys
sys.path.append(str(Path(__file__).parent.parent))
from config import (
    DB_CONFIG,
    DB_COLUMN_MAPPING,
    DB_NUMERIC_COLUMNS,
    DB_STRING_COLUMNS,
    DB_STRING_MAX_LENGTHS,
    DB_REQUIRED_COLUMNS
)


class DatabaseManager:
    """æ•°æ®åº“ç®¡ç†å™¨"""
    
    def __init__(self, config: Optional[dict] = None):
        """
        åˆå§‹åŒ–æ•°æ®åº“ç®¡ç†å™¨
        
        Args:
            config: æ•°æ®åº“é…ç½®å­—å…¸ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤é…ç½®
        """
        self.config = config if config else DB_CONFIG
        self.engine = None
        self.connected = False
    
    def connect(self) -> bool:
        """
        å»ºç«‹æ•°æ®åº“è¿æ¥
        
        Returns:
            è¿æ¥æ˜¯å¦æˆåŠŸ
        """
        try:
            connection_string = (
                f"mysql+pymysql://{self.config['user']}:{self.config['password']}@"
                f"{self.config['host']}:{self.config['port']}/{self.config['database']}"
            )
            self.engine = create_engine(connection_string)
            
            # æµ‹è¯•è¿æ¥
            with self.engine.connect() as conn:
                pass
            
            self.connected = True
            print("âœ“ æ•°æ®åº“è¿æ¥æˆåŠŸ")
            return True
        except Exception as e:
            print(f"âœ— æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
            self.connected = False
            return False
    
    def check_table_exists(self, table_name: Optional[str] = None) -> bool:
        """
        æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
        
        Args:
            table_name: è¡¨åï¼Œé»˜è®¤ä½¿ç”¨é…ç½®ä¸­çš„è¡¨å
            
        Returns:
            è¡¨æ˜¯å¦å­˜åœ¨
        """
        if not self.connected:
            return False
        
        table_name = table_name or self.config.get('table_name', 'QCR_data')
        
        try:
            result = pd.read_sql(
                "SELECT COUNT(*) as count FROM information_schema.tables "
                "WHERE table_schema = %s AND table_name = %s",
                self.engine,
                params=(self.config['database'], table_name)
            )
            return result['count'].iloc[0] > 0
        except Exception as e:
            print(f"æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨å¤±è´¥: {e}")
            return False
    
    def get_existing_service_orders(self, table_name: Optional[str] = None) -> list:
        """
        è·å–æ•°æ®åº“ä¸­å·²å­˜åœ¨çš„æœåŠ¡å•å·åˆ—è¡¨
        
        Args:
            table_name: è¡¨åï¼Œé»˜è®¤ä½¿ç”¨é…ç½®ä¸­çš„è¡¨å
            
        Returns:
            æœåŠ¡å•å·åˆ—è¡¨
        """
        if not self.connected:
            return []
        
        table_name = table_name or self.config.get('table_name', 'QCR_data')
        
        if not self.check_table_exists(table_name):
            print(f"è¡¨ {table_name} ä¸å­˜åœ¨ï¼Œå°†åˆ›å»ºæ–°è¡¨")
            return []
        
        try:
            existing_orders = pd.read_sql(
                f"SELECT service_order_id FROM {table_name}",
                self.engine
            )['service_order_id'].astype(str).tolist()
            print(f"âœ“ æ•°æ®åº“ä¸­å·²å­˜åœ¨ {len(existing_orders)} ä¸ªæœåŠ¡å•å·")
            return existing_orders
        except Exception as e:
            print(f"æŸ¥è¯¢æœåŠ¡å•å·å¤±è´¥: {e}")
            return []
    
    def filter_new_records(self, df: pd.DataFrame, service_order_column: str) -> pd.DataFrame:
        """
        ç­›é€‰æ•°æ®åº“ä¸­ä¸å­˜åœ¨çš„æ–°è®°å½•
        
        Args:
            df: åŸå§‹æ•°æ®DataFrame
            service_order_column: æœåŠ¡å•å·åˆ—å
            
        Returns:
            æ–°è®°å½•çš„DataFrame
        """
        if service_order_column not in df.columns:
            print(f"è­¦å‘Šï¼šæœªæ‰¾åˆ°'{service_order_column}'åˆ—ï¼Œè·³è¿‡æ•°æ®åº“å»é‡")
            return df
        
        # è·å–å½“å‰æ•°æ®ä¸­çš„æœåŠ¡å•å·
        current_orders = df[service_order_column].dropna().astype(str).tolist()
        print(f"å½“å‰æ•°æ®åŒ…å« {len(current_orders)} ä¸ªæœåŠ¡å•å·")
        
        # è·å–æ•°æ®åº“ä¸­å·²å­˜åœ¨çš„æœåŠ¡å•å·
        existing_orders = self.get_existing_service_orders()
        
        # ç­›é€‰æ–°æœåŠ¡å•å·
        new_orders = [order for order in current_orders if order not in existing_orders]
        print(f"æ–°æœåŠ¡å•å·æ•°é‡: {len(new_orders)}")
        
        # ç­›é€‰æ–°æ•°æ®
        df_new = df[df[service_order_column].astype(str).isin(new_orders)].copy()
        
        if len(df_new) == 0:
            print("æ²¡æœ‰æ–°æ•°æ®éœ€è¦å¯¼å…¥å’Œåˆ†æ")
        else:
            print(f"âœ“ ç­›é€‰å‡º {len(df_new)} æ¡æ–°è®°å½•")
        
        return df_new
    
    def prepare_for_import(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        å‡†å¤‡æ•°æ®ä»¥å¯¼å…¥æ•°æ®åº“
        åŒ…æ‹¬ï¼šåˆ—é‡å‘½åã€æ•°æ®ç±»å‹è½¬æ¢ã€æ•°æ®æ¸…æ´—
        
        Args:
            df: åŸå§‹æ•°æ®DataFrame
            
        Returns:
            å‡†å¤‡å¥½çš„DataFrame
        """
        df_import = df.copy()
        
        # 1. åˆ—é‡å‘½å - ä¼˜å…ˆå®Œå…¨åŒ¹é…ï¼Œç„¶åæ‰æ˜¯åŒ…å«åŒ¹é…
        column_mapping = {}
        for col in df_import.columns:
            col_str = str(col).strip()
            # å…ˆå°è¯•å®Œå…¨åŒ¹é…
            if col_str in DB_COLUMN_MAPPING:
                column_mapping[col] = DB_COLUMN_MAPPING[col_str]
            else:
                # å†å°è¯•åŒ…å«åŒ¹é…ï¼ˆå‘åå…¼å®¹ï¼‰
                for key, value in DB_COLUMN_MAPPING.items():
                    if key in col_str:
                        column_mapping[col] = value
                        break
        
        df_import = df_import.rename(columns=column_mapping)
        
        print(f"  åˆ—æ˜ å°„: {len(column_mapping)} ä¸ªåˆ—è¢«æ˜ å°„")
        
        # 2. ç¡®ä¿å¿…éœ€çš„åˆ—å­˜åœ¨
        for col in DB_REQUIRED_COLUMNS:
            if col not in df_import.columns:
                df_import[col] = ''
        
        # 3. å¤„ç†æ—¥æœŸåˆ—
        if 'date' in df_import.columns:
            df_import['date'] = pd.to_datetime(df_import['date'], errors='coerce')
            # å¡«å……ç©ºæ—¥æœŸä¸ºå½“å‰æ—¥æœŸ
            df_import['date'] = df_import['date'].fillna(pd.Timestamp.now())
            df_import['date'] = df_import['date'].dt.strftime('%Y-%m-%d')
        
        # 4. å¤„ç†æ•°å€¼åˆ—ï¼ˆNOT NULLçº¦æŸï¼‰
        for col in DB_NUMERIC_COLUMNS:
            if col in df_import.columns:
                df_import[col] = pd.to_numeric(df_import[col], errors='coerce')
                # å¯¹äºNOT NULLçš„æ•°å€¼å­—æ®µï¼Œä½¿ç”¨0å¡«å……ç©ºå€¼
                df_import[col] = df_import[col].fillna(0)
                df_import[col] = df_import[col].astype('int64')  # ä½¿ç”¨int64è€Œä¸æ˜¯Int64ï¼Œé¿å…å¯ç©ºç±»å‹
        
        # 5. å¤„ç†å­—ç¬¦ä¸²åˆ—ï¼ˆNOT NULLçº¦æŸï¼‰
        for col in DB_STRING_COLUMNS:
            if col in df_import.columns:
                # å…ˆè½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼Œç„¶åå¡«å……ç©ºå€¼
                df_import[col] = df_import[col].astype(str)
                # å°†'nan', 'None', 'NaN'ç­‰æ›¿æ¢ä¸ºç©ºå­—ç¬¦ä¸²
                df_import[col] = df_import[col].replace(['nan', 'None', 'NaN', '<NA>'], '')
                df_import[col] = df_import[col].fillna('')
                df_import[col] = df_import[col].str.strip()
                # å­—ç¬¦ä¸²é•¿åº¦é™åˆ¶
                if col in DB_STRING_MAX_LENGTHS:
                    df_import[col] = df_import[col].str[:DB_STRING_MAX_LENGTHS[col]]
                # å¯¹äºç‰¹å®šçš„NOT NULLå­—æ®µï¼Œå¦‚æœä¸ºç©ºåˆ™å¡«å……é»˜è®¤å€¼
                if col in ['product_name', 'sn_code', 'customer_account', 'audit_reason', 'mtm']:
                    df_import[col] = df_import[col].replace('', 'æœªçŸ¥')
                if col == 'issue_description':
                    df_import[col] = df_import[col].replace('', 'æ— æè¿°')
                if col in ['issue_category', 'category']:
                    df_import[col] = df_import[col].replace('', 'æœªåˆ†ç±»')
        
        # 6. åˆ é™¤å…³é”®å­—æ®µæ— æ•ˆçš„è¡Œ
        if 'service_order_id' in df_import.columns:
            before_drop = len(df_import)
            # åˆ é™¤æœåŠ¡å•å·ä¸º0æˆ–ç©ºçš„è®°å½•
            df_import = df_import[df_import['service_order_id'] > 0]
            after_drop = len(df_import)
            if before_drop > after_drop:
                print(f"  åˆ é™¤äº† {before_drop - after_drop} æ¡æœåŠ¡å•å·æ— æ•ˆçš„è®°å½•")
        
        # 7. åªé€‰æ‹©æ•°æ®åº“éœ€è¦çš„åˆ—ï¼ˆå¦‚æœåˆ—å­˜åœ¨ï¼‰
        available_columns = [col for col in DB_REQUIRED_COLUMNS if col in df_import.columns]
        missing_columns = [col for col in DB_REQUIRED_COLUMNS if col not in df_import.columns]
        
        if missing_columns:
            print(f"  è­¦å‘Š: ä»¥ä¸‹å¿…éœ€åˆ—ç¼ºå¤±: {missing_columns}")
            print(f"  å¯ç”¨çš„åˆ—: {df_import.columns.tolist()}")
            # ä¸ºç¼ºå¤±çš„åˆ—å¡«å……é»˜è®¤å€¼
            for col in missing_columns:
                if col in DB_NUMERIC_COLUMNS:
                    df_import[col] = 0
                else:
                    df_import[col] = ''
        
        df_import = df_import[DB_REQUIRED_COLUMNS]
        
        return df_import
    
    def import_data(self, df: pd.DataFrame, table_name: Optional[str] = None) -> bool:
        """
        å¯¼å…¥æ•°æ®åˆ°æ•°æ®åº“
        
        Args:
            df: è¦å¯¼å…¥çš„DataFrame
            table_name: è¡¨åï¼Œé»˜è®¤ä½¿ç”¨é…ç½®ä¸­çš„è¡¨å
            
        Returns:
            å¯¼å…¥æ˜¯å¦æˆåŠŸ
        """
        if not self.connected:
            print("é”™è¯¯ï¼šæ•°æ®åº“æœªè¿æ¥")
            return False
        
        if len(df) == 0:
            print("æ²¡æœ‰æ•°æ®éœ€è¦å¯¼å…¥")
            return True
        
        table_name = table_name or self.config.get('table_name', 'QCR_data')
        
        try:
            # æ˜¾ç¤ºå‡†å¤‡å¯¼å…¥çš„æ•°æ®ä¿¡æ¯
            print(f"  å‡†å¤‡å¯¼å…¥ {len(df)} æ¡è®°å½•åˆ°è¡¨ {table_name}")
            print(f"  åˆ—: {df.columns.tolist()}")
            
            # æ£€æŸ¥æ•°æ®ä¸­æ˜¯å¦æœ‰NULLå€¼ï¼ˆé’ˆå¯¹NOT NULLå­—æ®µï¼‰
            null_counts = df.isnull().sum()
            if null_counts.sum() > 0:
                print("  è­¦å‘Šï¼šå‘ç°ä»¥ä¸‹åˆ—åŒ…å«ç©ºå€¼ï¼š")
                for col, count in null_counts[null_counts > 0].items():
                    print(f"    {col}: {count} ä¸ªç©ºå€¼")
            
            # ä½¿ç”¨å•æ¡æ’å…¥æ¨¡å¼ï¼Œæ›´å®¹æ˜“å®šä½é—®é¢˜
            # å¦‚æœæ•°æ®é‡å°äº100æ¡ï¼Œä½¿ç”¨å•æ¡æ’å…¥ï¼›å¦åˆ™ä½¿ç”¨æ‰¹é‡æ’å…¥
            if len(df) < 100:
                df.to_sql(
                    table_name,
                    self.engine,
                    if_exists='append',
                    index=False,
                    method=None  # ä½¿ç”¨é»˜è®¤æ–¹æ³•ï¼Œé€æ¡æ’å…¥
                )
            else:
                # æ‰¹é‡æ’å…¥ï¼Œæé«˜æ•ˆç‡
                df.to_sql(
                    table_name,
                    self.engine,
                    if_exists='append',
                    index=False,
                    method='multi',
                    chunksize=100  # æ¯æ¬¡æ’å…¥100æ¡
                )
            
            print(f"âœ“ æˆåŠŸå¯¼å…¥ {len(df)} æ¡è®°å½•åˆ°æ•°æ®åº“è¡¨ {table_name}")
            return True
        except Exception as e:
            print(f"âœ— å¯¼å…¥æ•°æ®å¤±è´¥: {e}")
            print(f"  é”™è¯¯ç±»å‹: {type(e).__name__}")
            
            # å°è¯•æ‰¾å‡ºæœ‰é—®é¢˜çš„è®°å½•
            print("\nå°è¯•è¯Šæ–­é—®é¢˜...")
            try:
                # æ˜¾ç¤ºå‰å‡ è¡Œæ•°æ®çš„ä¿¡æ¯
                print("\nå‰3æ¡æ•°æ®æ ·ä¾‹ï¼š")
                for idx in range(min(3, len(df))):
                    print(f"\nè®°å½• {idx + 1}:")
                    for col in df.columns:
                        val = df.iloc[idx][col]
                        val_type = type(val).__name__
                        print(f"  {col}: {val} (ç±»å‹: {val_type})")
            except Exception as diag_e:
                print(f"è¯Šæ–­å¤±è´¥: {diag_e}")
            
            import traceback
            print("\nè¯¦ç»†é”™è¯¯ä¿¡æ¯:")
            traceback.print_exc()
            return False
    
    def check_and_import_new_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        å®Œæ•´æµç¨‹ï¼šæ£€æŸ¥ã€ç­›é€‰æ–°æ•°æ®ã€å¯¼å…¥æ•°æ®åº“
        
        Args:
            df: åŸå§‹æ•°æ®DataFrame
            
        Returns:
            æ–°æ•°æ®çš„DataFrame
        """
        try:
            # 1. è¿æ¥æ•°æ®åº“
            if not self.connected:
                if not self.connect():
                    print("æ•°æ®åº“è¿æ¥å¤±è´¥ï¼Œè·³è¿‡æ•°æ®åº“æ“ä½œ")
                    return df
            
            # 2. æŸ¥æ‰¾æœåŠ¡å•å·åˆ—
            service_order_column = None
            for col in df.columns:
                if 'æœåŠ¡å•å·' in str(col):
                    service_order_column = col
                    break
            
            if service_order_column is None:
                print("è­¦å‘Šï¼šæœªæ‰¾åˆ°'æœåŠ¡å•å·'åˆ—ï¼Œè·³è¿‡æ•°æ®åº“å»é‡")
                return df
            
            # 3. ç­›é€‰æ–°æ•°æ®
            df_new = self.filter_new_records(df, service_order_column)
            
            if len(df_new) == 0:
                return df_new
            
            # 4. å‡†å¤‡æ•°æ®
            df_import = self.prepare_for_import(df_new)
            
            # 5. å¯¼å…¥æ•°æ®åº“
            self.import_data(df_import)
            
            # è¿”å›æ–°æ•°æ®ç”¨äºåç»­åˆ†æ
            return df_new
            
        except Exception as e:
            print(f"æ•°æ®åº“æ“ä½œå¤±è´¥: {e}")
            print("å°†ç»§ç»­åˆ†æåŸå§‹æ•°æ®ï¼Œè·³è¿‡æ•°æ®åº“æ£€æŸ¥å’Œå¯¼å…¥")
            return df
    
    def query_by_date_range(self, start_date: str, end_date: str, 
                           table_name: Optional[str] = None) -> pd.DataFrame:
        """
        ä»æ•°æ®åº“æŒ‰æ—¥æœŸèŒƒå›´æŸ¥è¯¢æ•°æ®
        
        Args:
            start_date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
            end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD)
            table_name: è¡¨åï¼Œé»˜è®¤ä½¿ç”¨é…ç½®ä¸­çš„è¡¨å
            
        Returns:
            æŸ¥è¯¢ç»“æœçš„DataFrame
        """
        if not self.connected:
            if not self.connect():
                print("æ•°æ®åº“è¿æ¥å¤±è´¥")
                return pd.DataFrame()
        
        table_name = table_name or self.config.get('table_name', 'QCR_data')
        
        if not self.check_table_exists(table_name):
            print(f"è¡¨ {table_name} ä¸å­˜åœ¨")
            return pd.DataFrame()
        
        try:
            query = f"""
                SELECT * FROM {table_name}
                WHERE date >= %s AND date <= %s
                ORDER BY date DESC
            """
            df = pd.read_sql(query, self.engine, params=(start_date, end_date))
            print(f"âœ“ ä»æ•°æ®åº“æŸ¥è¯¢åˆ° {len(df)} æ¡è®°å½• ({start_date} ~ {end_date})")
            
            # å°†æ•°æ®åº“åˆ—åæ˜ å°„å›Excelåˆ—åï¼ˆåå‘æ˜ å°„ï¼‰
            reverse_mapping = {v: k for k, v in DB_COLUMN_MAPPING.items()}
            df = df.rename(columns=reverse_mapping)
            
            return df
        except Exception as e:
            print(f"âœ— æŸ¥è¯¢æ•°æ®å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return pd.DataFrame()
    
    def update_mtm_mappings(self, mtm_file: str) -> bool:
        """
        ä»MTMè¡¨æ ¼æ›´æ–°æ•°æ®åº“ä¸­çš„product_name
        
        Args:
            mtm_file: MTMæ˜ å°„è¡¨Excelæ–‡ä»¶è·¯å¾„
            
        Returns:
            æ›´æ–°æ˜¯å¦æˆåŠŸ
        """
        if not self.connected:
            if not self.connect():
                print("æ•°æ®åº“è¿æ¥å¤±è´¥")
                return False
        
        try:
            # è¯»å–MTMè¡¨æ ¼
            print(f"ğŸ“– è¯»å–MTMæ˜ å°„è¡¨: {mtm_file}")
            mtm_df = pd.read_excel(mtm_file)
            
            # æŸ¥æ‰¾MTMå’Œäº§å“åç§°åˆ—
            mtm_col = None
            product_col = None
            
            for col in mtm_df.columns:
                col_lower = str(col).lower().strip()
                if 'mtm' in col_lower and mtm_col is None:
                    mtm_col = col
                if ('product' in col_lower or 'äº§å“' in col_lower or 'æœºå‹' in col_lower) and product_col is None:
                    product_col = col
            
            if mtm_col is None or product_col is None:
                print(f"âœ— MTMè¡¨æ ¼æ ¼å¼ä¸æ­£ç¡®ï¼Œéœ€è¦åŒ…å«MTMåˆ—å’Œäº§å“åç§°åˆ—")
                print(f"   æ‰¾åˆ°çš„åˆ—: {mtm_df.columns.tolist()}")
                return False
            
            print(f"âœ“ è¯†åˆ«åˆ—æ˜ å°„: MTMåˆ—='{mtm_col}', äº§å“åç§°åˆ—='{product_col}'")
            
            # æ¸…ç†æ•°æ®
            mtm_df = mtm_df[[mtm_col, product_col]].dropna()
            mtm_df[mtm_col] = mtm_df[mtm_col].astype(str).str.strip()
            mtm_df[product_col] = mtm_df[product_col].astype(str).str.strip()
            
            print(f"âœ“ è¯»å–åˆ° {len(mtm_df)} æ¡MTMæ˜ å°„è®°å½•")
            
            # æ‰¹é‡æ›´æ–°æ•°æ®åº“
            table_name = self.config.get('table_name', 'QCR_data')
            updated_count = 0
            
            print(f"\nğŸ”„ å¼€å§‹æ›´æ–°æ•°æ®åº“è¡¨ {table_name} ä¸­çš„product_name...")
            
            with self.engine.begin() as conn:
                for idx, row in mtm_df.iterrows():
                    mtm_code = row[mtm_col]
                    product_name = row[product_col]
                    
                    # æ‰§è¡ŒUPDATEï¼ˆä½¿ç”¨å‘½åå‚æ•°ï¼‰
                    result = conn.execute(
                        text(f"""
                        UPDATE {table_name}
                        SET product_name = :product_name
                        WHERE mtm = :mtm_code
                        """),
                        {"product_name": product_name, "mtm_code": mtm_code}
                    )
                    
                    if result.rowcount > 0:
                        updated_count += result.rowcount
                        if (idx + 1) % 10 == 0:
                            print(f"  å·²å¤„ç† {idx + 1}/{len(mtm_df)} æ¡æ˜ å°„è®°å½•...")
            
            print(f"\nâœ… MTMæ˜ å°„æ›´æ–°å®Œæˆï¼")
            print(f"   å¤„ç†äº† {len(mtm_df)} æ¡æ˜ å°„è®°å½•")
            print(f"   æ›´æ–°äº† {updated_count} æ¡æ•°æ®åº“è®°å½•")
            
            return True
            
        except Exception as e:
            print(f"âœ— æ›´æ–°MTMæ˜ å°„å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def import_excel_to_db(self, excel_file: str) -> bool:
        """
        ç‹¬ç«‹åŠŸèƒ½ï¼šå°†Excelæ•°æ®å¯¼å…¥æ•°æ®åº“ï¼ˆå¸¦å»é‡ï¼‰
        
        Args:
            excel_file: Excelæ–‡ä»¶è·¯å¾„
            
        Returns:
            å¯¼å…¥æ˜¯å¦æˆåŠŸ
        """
        if not self.connected:
            if not self.connect():
                print("æ•°æ®åº“è¿æ¥å¤±è´¥")
                return False
        
        try:
            # è¯»å–Excel
            print(f"\nğŸ“– è¯»å–Excelæ–‡ä»¶: {excel_file}")
            df = pd.read_excel(excel_file, sheet_name=0)
            print(f"âœ“ è¯»å–åˆ° {len(df)} æ¡è®°å½•")
            
            # å¤„ç†æ—¥æœŸåˆ—ï¼ˆå‡è®¾ç¬¬ä¸€åˆ—æ˜¯æ—¥æœŸï¼‰
            date_column = df.columns[0]
            df[date_column] = pd.to_datetime(df[date_column]).dt.date
            
            # æŸ¥æ‰¾æœåŠ¡å•å·åˆ—
            service_order_column = None
            for col in df.columns:
                if 'æœåŠ¡å•å·' in str(col):
                    service_order_column = col
                    break
            
            if service_order_column is None:
                print("âœ— æœªæ‰¾åˆ°'æœåŠ¡å•å·'åˆ—ï¼Œæ— æ³•è¿›è¡Œå»é‡")
                return False
            
            # å»é‡æ£€æµ‹
            print(f"\nğŸ” å¼€å§‹æ•°æ®åº“å»é‡æ£€æµ‹...")
            df_new = self.filter_new_records(df, service_order_column)
            
            if len(df_new) == 0:
                print("âœ“ æ²¡æœ‰æ–°æ•°æ®éœ€è¦å¯¼å…¥")
                return True
            
            # å‡†å¤‡æ•°æ®
            print(f"\nâš™ï¸  å‡†å¤‡æ•°æ®...")
            df_import = self.prepare_for_import(df_new)
            
            # å¯¼å…¥æ•°æ®åº“
            print(f"\nğŸ“¥ å¯¼å…¥æ•°æ®åˆ°æ•°æ®åº“...")
            success = self.import_data(df_import)
            
            if success:
                print(f"\nâœ… Excelå¯¼å…¥å®Œæˆï¼")
                print(f"   åŸå§‹è®°å½•: {len(df)} æ¡")
                print(f"   æ–°è®°å½•: {len(df_new)} æ¡")
                print(f"   å·²å¯¼å…¥æ•°æ®åº“")
            
            return success
            
        except Exception as e:
            print(f"âœ— å¯¼å…¥Excelå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def close(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        if self.engine:
            self.engine.dispose()
            self.connected = False
            print("âœ“ æ•°æ®åº“è¿æ¥å·²å…³é—­")

