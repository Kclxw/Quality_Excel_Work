# -*- coding: utf-8 -*-
"""
=============================================================================
æ•°æ®åˆ†ææ¨¡å—
=============================================================================
è´Ÿè´£æ•°æ®ç»Ÿè®¡åˆ†æå’Œå›¾è¡¨ç”Ÿæˆ
=============================================================================
"""

import pandas as pd
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from datetime import date, datetime, timedelta
import re

import sys
sys.path.append(str(Path(__file__).parent.parent))
from config import (
    AUDIT_REASONS,
    MATPLOTLIB_FONTS,
    CHART_STYLE
)

# è®¾ç½®ä¸­æ–‡å­—ä½“
matplotlib.rcParams['font.family'] = MATPLOTLIB_FONTS
matplotlib.rcParams['axes.unicode_minus'] = False

# å¤„ç†å­—ä½“è­¦å‘Š
import warnings
warnings.filterwarnings("ignore", category=UserWarning, message=".*Glyph.*missing.*")


def sanitize_filename(filename: str) -> str:
    """
    æ¸…ç†æ–‡ä»¶åä¸­çš„éæ³•å­—ç¬¦
    
    Args:
        filename: åŸå§‹æ–‡ä»¶å
        
    Returns:
        æ¸…ç†åçš„æ–‡ä»¶å
    """
    # Windowséæ³•å­—ç¬¦ï¼š<>:"/\|?*
    illegal_chars = r'[<>:\"/\\|?*]'
    filename = re.sub(illegal_chars, ' ', filename)
    filename = filename.strip()
    if len(filename) > 200:
        filename = filename[:200]
    return filename


def get_week_workday_range(reference_date: Optional[date] = None) -> Tuple[str, str]:
    """
    è·å–æœ¬å‘¨å·¥ä½œæ—¥èŒƒå›´ï¼ˆå‘¨ä¸€åˆ°å‘¨äº”ï¼‰
    
    Args:
        reference_date: å‚è€ƒæ—¥æœŸï¼Œé»˜è®¤ä¸ºä»Šå¤©
        
    Returns:
        (å‘¨ä¸€æ—¥æœŸ, å‘¨äº”æ—¥æœŸ) å…ƒç»„
    """
    today = reference_date if reference_date else datetime.today().date()
    monday = today - timedelta(days=today.weekday())
    friday = monday + timedelta(days=4)
    return monday.strftime("%Y/%m/%d"), friday.strftime("%Y/%m/%d")


def determine_coverage_range(df: pd.DataFrame, date_column: str,
                            start_date: Optional[date],
                            end_date: Optional[date]) -> Tuple[str, str]:
    """
    ç¡®å®šæ•°æ®è¦†ç›–çš„æ—¥æœŸèŒƒå›´
    
    Args:
        df: æ•°æ®DataFrame
        date_column: æ—¥æœŸåˆ—å
        start_date: å¼€å§‹æ—¥æœŸ
        end_date: ç»“æŸæ—¥æœŸ
        
    Returns:
        (å¼€å§‹æ—¥æœŸå­—ç¬¦ä¸², ç»“æŸæ—¥æœŸå­—ç¬¦ä¸²) å…ƒç»„
    """
    if df.empty:
        return ("-", "-")
    
    actual_start = start_date if start_date else df[date_column].min()
    actual_end = end_date if end_date else df[date_column].max()
    
    # å°† pandas Timestamp è½¬æ¢ä¸º date å¯¹è±¡
    if hasattr(actual_start, 'date') and callable(actual_start.date):
        actual_start = actual_start.date()
    if hasattr(actual_end, 'date') and callable(actual_end.date):
        actual_end = actual_end.date()
    
    return actual_start.strftime("%Y/%m/%d"), actual_end.strftime("%Y/%m/%d")


class DataAnalyzer:
    """æ•°æ®åˆ†æå™¨"""
    
    def __init__(self, output_dir: Path):
        """
        åˆå§‹åŒ–æ•°æ®åˆ†æå™¨
        
        Args:
            output_dir: è¾“å‡ºç›®å½•è·¯å¾„
        """
        self.output_dir = output_dir
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # åˆ›å»ºè¯¦ç»†æ•°æ®ç›®å½•
        self.detailed_dir_7d = output_dir / "è¯¦ç»†æ•°æ®" / "7å¤©æ— ç†ç”±"
        self.detailed_dir_non7d = output_dir / "è¯¦ç»†æ•°æ®" / "é7å¤©æ— ç†ç”±"
        self.detailed_dir_7d.mkdir(parents=True, exist_ok=True)
        self.detailed_dir_non7d.mkdir(parents=True, exist_ok=True)
    
    def analyze_audit_reasons(self, df: pd.DataFrame) -> Tuple[pd.DataFrame, Path]:
        """
        ç»Ÿè®¡å®¡æ ¸åŸå› 
        
        Args:
            df: æ•°æ®DataFrame
            
        Returns:
            (ç»Ÿè®¡ç»“æœDataFrame, å›¾è¡¨è·¯å¾„)
        """
        counts = {r: int((df["å®¡æ ¸åŸå› "] == r).sum()) for r in AUDIT_REASONS}
        
        summary_df = pd.DataFrame(list(counts.items()), columns=["å®¡æ ¸åŸå› ", "æ•°é‡"])
        total_count = summary_df["æ•°é‡"].sum()
        summary_df["å æ¯”"] = (summary_df["æ•°é‡"] / total_count * 100).round(2)
        
        # ä¿å­˜Excel
        summary_df.to_excel(self.output_dir / "å®¡æ ¸åŸå› ç»Ÿè®¡.xlsx", index=False)
        
        # ç”Ÿæˆé¥¼å›¾
        plt.figure(figsize=CHART_STYLE['reason_chart_size'])
        plt.pie(summary_df["æ•°é‡"], labels=summary_df["å®¡æ ¸åŸå› "], autopct="%1.1f%%")
        plt.title("å®¡æ ¸åŸå› å æ¯”")
        plt.tight_layout()
        chart_path = self.output_dir / "å®¡æ ¸åŸå› å æ¯”.png"
        plt.savefig(chart_path)
        plt.close()
        
        print(f"âœ“ å®¡æ ¸åŸå› ç»Ÿè®¡å®Œæˆï¼Œå…± {total_count} æ¡è®°å½•")
        
        return summary_df, chart_path
    
    def analyze_model_distribution(self, df: pd.DataFrame, suffix: str) -> Tuple[pd.DataFrame, Optional[Path]]:
        """
        ç»Ÿè®¡æœºå‹åˆ†å¸ƒ
        
        Args:
            df: æ•°æ®DataFrame
            suffix: åˆ†ç±»åç¼€ï¼ˆ7å¤©æ— ç†ç”± æˆ– é7å¤©æ— ç†ç”±ï¼‰
            
        Returns:
            (ç»Ÿè®¡ç»“æœDataFrame, å›¾è¡¨è·¯å¾„)
        """
        if len(df) == 0:
            print(f"è­¦å‘Šï¼š{suffix}æ•°æ®ä¸ºç©º")
            return pd.DataFrame(), None
        
        model_dist = (
            df["æœºå‹åç§°"]
            .value_counts()
            .rename_axis("æœºå‹åç§°")
            .reset_index(name="æ•°é‡")
            .assign(å æ¯”=lambda x: (x["æ•°é‡"] / x["æ•°é‡"].sum() * 100).round(1))
        )
        
        # ä¿å­˜Excel
        model_dist.to_excel(self.output_dir / f"{suffix}_æœºå‹åˆ†å¸ƒ.xlsx", index=False)
        
        # ç”Ÿæˆé¥¼å›¾
        plt.figure(figsize=CHART_STYLE['pie_chart_size'])
        plt.pie(model_dist["æ•°é‡"], labels=model_dist["æœºå‹åç§°"], autopct="%1.1f%%")
        plt.title(f"{suffix} - æœºå‹åˆ†å¸ƒ")
        plt.tight_layout()
        chart_path = self.output_dir / f"{suffix}_æœºå‹åˆ†å¸ƒ.png"
        plt.savefig(chart_path)
        plt.close()
        
        print(f"âœ“ {suffix}æœºå‹åˆ†å¸ƒç»Ÿè®¡å®Œæˆï¼Œå…± {len(df)} æ¡è®°å½•ï¼Œ{len(model_dist)} ä¸ªæœºå‹")
        
        return model_dist, chart_path
    
    def analyze_model_issues(self, df: pd.DataFrame, suffix: str) -> List[Dict]:
        """
        æŒ‰æœºå‹åˆ†æé—®é¢˜åˆ†ç±»
        
        Args:
            df: æ•°æ®DataFrame
            suffix: åˆ†ç±»åç¼€ï¼ˆ7å¤©æ— ç†ç”± æˆ– é7å¤©æ— ç†ç”±ï¼‰
            
        Returns:
            æœºå‹åˆ†æç»“æœåˆ—è¡¨
        """
        if len(df) == 0:
            print(f"è­¦å‘Šï¼š{suffix}æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡æœºå‹åˆ†æ")
            return []
        
        # é€‰æ‹©è¯¦ç»†æ•°æ®ç›®å½•
        detailed_dir = self.detailed_dir_7d if suffix == "7å¤©æ— ç†ç”±" else self.detailed_dir_non7d
        
        # é7å¤©æ— ç†ç”±æ•°æ®ï¼šè¿‡æ»¤æ‰é—®é¢˜æè¿°ä¸ºç©ºçš„è¡Œ
        if suffix == "é7å¤©æ— ç†ç”±" and "é—®é¢˜æè¿°" in df.columns:
            original_len = len(df)
            df = df[df["é—®é¢˜æè¿°"].notna() & (df["é—®é¢˜æè¿°"] != "")]
            print(f"å·²è¿‡æ»¤ç©ºé—®é¢˜æè¿°è¡Œï¼Œä» {original_len} æ¡å‡å°‘åˆ° {len(df)} æ¡è®°å½•")
        
        summaries = []
        
        for model in df["æœºå‹åç§°"].unique():
            # æ¸…ç†æœºå‹åç§°
            clean_model = sanitize_filename(str(model))
            
            # åˆ›å»ºæœºå‹æ–‡ä»¶å¤¹
            model_dir = detailed_dir / clean_model
            model_dir.mkdir(parents=True, exist_ok=True)
            
            # è·å–è¯¥æœºå‹çš„æ‰€æœ‰æ•°æ®
            model_data = df[df["æœºå‹åç§°"] == model].copy()
            
            # ç»Ÿè®¡åˆ†ç±»é¢‘æ¬¡
            category_stats = (
                model_data["åˆ†ç±»"]
                .value_counts()
                .rename_axis("åˆ†ç±»")
                .reset_index(name="æ¬¡æ•°")
            )
            
            if "æ¬¡æ•°" in category_stats.columns and category_stats["æ¬¡æ•°"].sum() > 0:
                category_stats["å æ¯”"] = (category_stats["æ¬¡æ•°"] / category_stats["æ¬¡æ•°"].sum() * 100).round(1)
            else:
                category_stats["å æ¯”"] = 0
            
            # ä¿å­˜é¢‘æ¬¡ç»Ÿè®¡
            freq_filename = f"{clean_model}_{suffix}_åˆ†ç±»é¢‘æ¬¡.xlsx"
            freq_path = model_dir / freq_filename
            category_stats.to_excel(freq_path, index=False)
            
            # ä¿å­˜è¯¦ç»†æ•°æ®
            detailed_filename = f"{clean_model}_{suffix}_è¯¦ç»†æ•°æ®.xlsx"
            detailed_path = model_dir / detailed_filename
            model_data.to_excel(detailed_path, index=False)
            
            # ç”ŸæˆæŸ±çŠ¶å›¾
            plt.figure(figsize=CHART_STYLE['bar_chart_size'])
            bars = plt.bar(category_stats["åˆ†ç±»"], category_stats["æ¬¡æ•°"])
            plt.xticks(rotation=45, ha="right")
            plt.title(f"{model} - {suffix} - åˆ†ç±»é¢‘æ¬¡")
            
            # æ·»åŠ æ•°é‡æ ‡ç­¾
            for bar in bars:
                height = bar.get_height()
                plt.text(bar.get_x() + bar.get_width()/2., height,
                        f'{int(height)}', ha='center', va='bottom')
            
            plt.tight_layout()
            
            chart_filename = f"{clean_model}_{suffix}_æŸ±çŠ¶å›¾.png"
            chart_path = model_dir / chart_filename
            plt.savefig(chart_path)
            plt.close()
            
            print(f"  - {model}: {len(category_stats)} ä¸ªåˆ†ç±»ï¼Œ{len(model_data)} æ¡è®°å½•")
            
            # ä¿å­˜æ‘˜è¦ä¿¡æ¯
            model_summary = {
                "model": model,
                "clean_model": clean_model,
                "suffix": suffix,
                "category_df": category_stats,
                "chart_path": str(chart_path),
                "total_records": len(model_data)
            }
            summaries.append(model_summary)
        
        print(f"âœ“ {suffix}æœºå‹é—®é¢˜åˆ†æå®Œæˆï¼Œå…± {len(summaries)} ä¸ªæœºå‹")
        
        return summaries
    
    def generate_text_report(self, df: pd.DataFrame, df_7d: pd.DataFrame,
                           df_non_7d: pd.DataFrame, start_date: Optional[date],
                           end_date: Optional[date]):
        """
        ç”Ÿæˆæ–‡æœ¬åˆ†ææŠ¥å‘Š
        
        Args:
            df: å®Œæ•´æ•°æ®DataFrame
            df_7d: 7å¤©æ— ç†ç”±æ•°æ®
            df_non_7d: é7å¤©æ— ç†ç”±æ•°æ®
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
        """
        report_lines = []
        
        # 1. åŸºæœ¬ç»Ÿè®¡
        report_lines.append("="*60)
        report_lines.append("QCR æ•°æ®åˆ†ææŠ¥å‘Š")
        report_lines.append("="*60)
        report_lines.append(f"åˆ†ææ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report_lines.append(f"æ•°æ®èŒƒå›´: {start_date or 'æœ€æ—©'} è‡³ {end_date or 'æœ€æ–°'}")
        report_lines.append(f"æ•°æ®æ€»é‡: {len(df)} æ¡è®°å½•")
        report_lines.append("")
        
        # 2. æœºå‹ç»Ÿè®¡
        unique_models = df['æœºå‹åç§°'].unique()
        report_lines.append(f"æ¶‰åŠæœºå‹æ•°: {len(unique_models)} æ¬¾")
        report_lines.append(f"æœºå‹åˆ—è¡¨: {', '.join(unique_models[:10])}")
        if len(unique_models) > 10:
            report_lines.append(f"          ... ç­‰å…± {len(unique_models)} æ¬¾")
        report_lines.append("")
        
        # 3. å®¡æ ¸åŸå› ç»Ÿè®¡
        report_lines.append("å®¡æ ¸åŸå› ç»Ÿè®¡:")
        for reason in AUDIT_REASONS:
            count = (df['å®¡æ ¸åŸå› '] == reason).sum()
            percentage = (count / len(df) * 100) if len(df) > 0 else 0
            report_lines.append(f"  {reason}: {count} æ¡ ({percentage:.2f}%)")
        report_lines.append("")
        
        # 4. 7å¤©æ— ç†ç”±åˆ†æ
        if len(df_7d) > 0:
            report_lines.append("ä¸ƒå¤©æ— ç†ç”±æœºå‹TOP5:")
            model_7d_dist = df_7d['æœºå‹åç§°'].value_counts().head(5)
            for model, count in model_7d_dist.items():
                percentage = (count / len(df_7d) * 100)
                report_lines.append(f"  {model}: {count} æ¡ ({percentage:.1f}%)")
            report_lines.append("")
        
        # 5. é7å¤©æ— ç†ç”±åˆ†æ
        if len(df_non_7d) > 0:
            report_lines.append("éä¸ƒå¤©æ— ç†ç”±æœºå‹TOP5:")
            model_non_7d_dist = df_non_7d['æœºå‹åç§°'].value_counts().head(5)
            for model, count in model_non_7d_dist.items():
                percentage = (count / len(df_non_7d) * 100)
                report_lines.append(f"  {model}: {count} æ¡ ({percentage:.1f}%)")
            report_lines.append("")
        
        report_lines.append("="*60)
        report_lines.append("æŠ¥å‘Šç»“æŸ")
        report_lines.append("="*60)
        
        # ä¿å­˜æŠ¥å‘Š
        report_path = self.output_dir / "åˆ†ææŠ¥å‘Š.txt"
        with open(report_path, "w", encoding="utf-8") as f:
            f.write("\n".join(report_lines))
        
        print(f"âœ“ æ–‡æœ¬åˆ†ææŠ¥å‘Šå·²ç”Ÿæˆï¼š{report_path}")
    
    def analyze_top_issues(self, df: pd.DataFrame, top_n: int = 10) -> Dict:
        """
        åˆ†æTop N IssueåŠå…¶æœºå‹åˆ†å¸ƒ
        
        Args:
            df: æ•°æ®DataFrame
            top_n: Top Næ•°é‡
            
        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        if len(df) == 0 or 'åˆ†ç±»' not in df.columns:
            print("è­¦å‘Šï¼šæ•°æ®ä¸ºç©ºæˆ–ç¼ºå°‘'åˆ†ç±»'åˆ—")
            return {}
        
        print(f"\nğŸ“Š å¼€å§‹Top {top_n} Issueåˆ†æ...")
        
        # åˆ›å»ºTop Issueåˆ†æç›®å½•
        top_issue_dir = self.output_dir / "Top_Issueåˆ†æ"
        top_issue_dir.mkdir(parents=True, exist_ok=True)
        charts_dir = top_issue_dir / "charts"
        charts_dir.mkdir(parents=True, exist_ok=True)
        
        # 1. ç»Ÿè®¡Top N Issue
        issue_counts = df['åˆ†ç±»'].value_counts().head(top_n)
        
        # åˆ›å»ºç»Ÿè®¡è¡¨
        issue_stats = pd.DataFrame({
            'æ’å': range(1, len(issue_counts) + 1),
            'Issueåç§°': issue_counts.index,
            'æ•°é‡': issue_counts.values,
            'å æ¯”(%)': (issue_counts.values / len(df) * 100).round(2)
        })
        issue_stats['ç´¯è®¡å æ¯”(%)'] = issue_stats['å æ¯”(%)'].cumsum().round(2)
        
        print(f"âœ“ ç»Ÿè®¡äº†Top {len(issue_stats)} Issue")
        
        # 2. ç”ŸæˆTop Issueæ€»è§ˆå›¾
        plt.figure(figsize=(14, 7))
        bars = plt.bar(range(len(issue_stats)), issue_stats['æ•°é‡'],
                      color=plt.cm.Blues(range(len(issue_stats), 0, -1)))
        
        plt.xlabel("Issueåˆ†ç±»", fontsize=12)
        plt.ylabel("æ•°é‡", fontsize=12)
        plt.title(f"Top {top_n} Issueåˆ†å¸ƒ", fontsize=16, fontweight='bold')
        plt.xticks(range(len(issue_stats)), issue_stats['Issueåç§°'], rotation=45, ha='right')
        
        # æ·»åŠ æ•°é‡æ ‡ç­¾
        for i, bar in enumerate(bars):
            height = bar.get_height()
            percentage = issue_stats.iloc[i]['å æ¯”(%)']
            plt.text(bar.get_x() + bar.get_width()/2., height,
                   f'{int(height)}\n({percentage:.1f}%)',
                   ha='center', va='bottom', fontsize=10)
        
        plt.tight_layout()
        summary_chart_path = charts_dir / "Top_Issueæ€»è§ˆå›¾.png"
        plt.savefig(summary_chart_path, dpi=150)
        plt.close()
        print(f"âœ“ ç”ŸæˆTop Issueæ€»è§ˆå›¾")
        
        # 3. åˆ†ææ¯ä¸ªIssueçš„æœºå‹åˆ†å¸ƒ
        issue_details = []
        
        print(f"\nğŸ“ˆ åˆ†ææ¯ä¸ªIssueçš„æœºå‹åˆ†å¸ƒ...")
        for idx, row in issue_stats.iterrows():
            issue_name = row['Issueåç§°']
            issue_count = row['æ•°é‡']
            
            # ç­›é€‰è¯¥Issueçš„æ•°æ®
            issue_df = df[df['åˆ†ç±»'] == issue_name]
            
            # ç»Ÿè®¡æœºå‹åˆ†å¸ƒ
            model_dist = (
                issue_df['æœºå‹åç§°']
                .value_counts()
                .rename_axis('æœºå‹åç§°')
                .reset_index(name='æ•°é‡')
            )
            model_dist['å æ¯”(%)'] = (model_dist['æ•°é‡'] / issue_count * 100).round(2)
            
            # ç”Ÿæˆæœºå‹åˆ†å¸ƒå›¾
            if len(model_dist) >= 2:
                fig, ax = plt.subplots(figsize=(12, 6))
                
                # åªæ˜¾ç¤ºå‰15ä¸ªæœºå‹
                display_data = model_dist.head(15)
                bars = ax.barh(range(len(display_data)), display_data['æ•°é‡'])
                
                ax.set_yticks(range(len(display_data)))
                ax.set_yticklabels(display_data['æœºå‹åç§°'], fontsize=10)
                ax.set_xlabel("æ•°é‡", fontsize=12)
                ax.set_title(f"Issue: {issue_name}\næœºå‹åˆ†å¸ƒ (å…±{len(model_dist)}æ¬¾æœºå‹)", 
                           fontsize=12, fontweight='bold')
                
                # æ·»åŠ æ•°é‡æ ‡ç­¾
                for i, bar in enumerate(bars):
                    width = bar.get_width()
                    percentage = display_data.iloc[i]['å æ¯”(%)']
                    ax.text(width, bar.get_y() + bar.get_height()/2.,
                           f' {int(width)} ({percentage:.1f}%)',
                           ha='left', va='center', fontsize=9)
                
                plt.tight_layout()
                chart_filename = f"Issue{idx+1}_{sanitize_filename(issue_name)}_æœºå‹åˆ†å¸ƒ.png"
                chart_path = charts_dir / chart_filename
                plt.savefig(chart_path, dpi=150)
                plt.close()
            else:
                chart_path = None
            
            # ä¿å­˜Issueè¯¦æƒ…
            issue_details.append({
                'rank': idx + 1,
                'issue_name': issue_name,
                'count': issue_count,
                'percentage': row['å æ¯”(%)'],
                'cumulative_percentage': row['ç´¯è®¡å æ¯”(%)'],
                'model_count': len(model_dist),
                'model_dist': model_dist,
                'chart_path': str(chart_path) if chart_path else None
            })
            
            print(f"  - Issue #{idx+1}: {issue_name} ({issue_count}æ¡) -> {len(model_dist)}æ¬¾æœºå‹")
        
        # 4. ä¿å­˜Excelï¼ˆå¤šsheetï¼‰
        excel_path = top_issue_dir / "Top_Issueç»Ÿè®¡æ±‡æ€».xlsx"
        with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:
            # Sheet1: Top Nåˆ—è¡¨
            issue_stats.to_excel(writer, sheet_name='Top_Issueåˆ—è¡¨', index=False)
            
            # Sheet2~N+1: å„Issueæœºå‹åˆ†å¸ƒ
            for detail in issue_details:
                sheet_name = sanitize_filename(detail['issue_name'])[:31]
                detail['model_dist'].to_excel(writer, sheet_name=sheet_name, index=False)
        
        print(f"âœ“ Excelæ±‡æ€»å·²ä¿å­˜ï¼š{excel_path.name}")
        
        # 5. ç”Ÿæˆæ–‡æœ¬æŠ¥å‘Š
        self._generate_top_issue_text_report(df, issue_stats, issue_details, top_issue_dir, top_n)
        
        # è¿”å›ç»“æœ
        result = {
            'top_n': top_n,
            'total_records': len(df),
            'issue_stats': issue_stats,
            'issue_details': issue_details,
            'excel_path': str(excel_path),
            'summary_chart_path': str(summary_chart_path),
            'charts_dir': str(charts_dir)
        }
        
        print(f"\nâœ… Top Issueåˆ†æå®Œæˆï¼")
        print(f"   æ€»è®°å½•æ•°: {len(df)}")
        print(f"   Top {top_n} ç´¯è®¡å æ¯”: {issue_stats['ç´¯è®¡å æ¯”(%)'].iloc[-1]:.2f}%")
        print(f"   æ¶‰åŠæœºå‹æ•°: {df['æœºå‹åç§°'].nunique()} æ¬¾")
        
        return result
    
    def _generate_top_issue_text_report(self, df: pd.DataFrame, issue_stats: pd.DataFrame,
                                        issue_details: List[Dict], output_dir: Path, top_n: int):
        """
        ç”ŸæˆTop Issueæ–‡æœ¬åˆ†ææŠ¥å‘Š
        
        Args:
            df: åŸå§‹æ•°æ®
            issue_stats: Issueç»Ÿè®¡è¡¨
            issue_details: Issueè¯¦æƒ…åˆ—è¡¨
            output_dir: è¾“å‡ºç›®å½•
            top_n: Top N
        """
        report_lines = []
        
        report_lines.append("="*70)
        report_lines.append(f"Top {top_n} Issue åˆ†ææŠ¥å‘Š")
        report_lines.append("="*70)
        report_lines.append(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report_lines.append(f"æ•°æ®æ€»é‡: {len(df)} æ¡è®°å½•")
        report_lines.append(f"æ¶‰åŠæœºå‹: {df['æœºå‹åç§°'].nunique()} æ¬¾")
        report_lines.append("")
        
        # Top Issueæ¦‚è§ˆ
        report_lines.append(f"ä¸€ã€Top {top_n} Issueåˆ†å¸ƒæ¦‚è§ˆ")
        report_lines.append("-"*70)
        for idx, row in issue_stats.iterrows():
            report_lines.append(
                f"  {row['æ’å']}. {row['Issueåç§°']}: "
                f"{row['æ•°é‡']}æ¡ ({row['å æ¯”(%)']:.2f}%) "
                f"[ç´¯è®¡: {row['ç´¯è®¡å æ¯”(%)']:.2f}%]"
            )
        report_lines.append("")
        
        # æ¯ä¸ªIssueçš„æœºå‹åˆ†å¸ƒè¯¦æƒ…
        report_lines.append(f"äºŒã€Top Issue æœºå‹åˆ†å¸ƒè¯¦æƒ…")
        report_lines.append("-"*70)
        for detail in issue_details:
            report_lines.append(f"\nã€Issue #{detail['rank']}ã€‘{detail['issue_name']}")
            report_lines.append(f"  æ€»è®¡: {detail['count']} æ¡è®°å½• ({detail['percentage']:.2f}%)")
            report_lines.append(f"  æ¶‰åŠæœºå‹: {detail['model_count']} æ¬¾")
            report_lines.append(f"  ä¸»è¦æœºå‹åˆ†å¸ƒï¼ˆTop 5ï¼‰:")
            
            model_dist = detail['model_dist'].head(5)
            for m_idx, m_row in model_dist.iterrows():
                report_lines.append(
                    f"    {m_idx+1}. {m_row['æœºå‹åç§°']}: "
                    f"{m_row['æ•°é‡']}æ¡ ({m_row['å æ¯”(%)']:.2f}%)"
                )
        
        report_lines.append("")
        report_lines.append("="*70)
        report_lines.append("æŠ¥å‘Šç»“æŸ")
        report_lines.append("="*70)
        
        # ä¿å­˜æŠ¥å‘Š
        report_path = output_dir / f"Top{top_n}_Issueåˆ†ææŠ¥å‘Š.txt"
        with open(report_path, "w", encoding="utf-8") as f:
            f.write("\n".join(report_lines))
        
        print(f"âœ“ æ–‡æœ¬æŠ¥å‘Šå·²ç”Ÿæˆï¼š{report_path.name}")

